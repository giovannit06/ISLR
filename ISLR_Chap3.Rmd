---
title: "ISLR - Chap3"
author: "GT"
date: "October 6, 2016"
output: html_document
---


## Chapter 3

### Simple Linear Regression

Here we load the `MASS` package, which is a very large collection of
data sets and functions. We also load the ISLR package, which includes
the data sets assoctiated with the book.

```{r}
library(MASS)
library(ISLR)
```

The `MASS` library contains the `Boston` data set, which records
`medv` (median house value) for 506 neighborhoods around Boston.
We will seek to predict `medv` using 13 predictors such as `rm` 
(average number of rooms per house), `age` (average age of houses), 
and `lstat` (percent of households with low socioeconomic status).

```{r}
names(Boston)
```

We will start by using the `lm()` function to fit a simple
linear regression model, with `medv` as the response and 
`lstat` as the predictor.

```{r}
lm.fit=lm(medv~lstat, data=Boston)
lm.fit
```

Some basic information about the model is output. For more
detailed information, we use `summary(lm.fit)`. This gives us
p-values and standard errors for the coefficients, as well as
the R-squared statistic and F-statistic for the model.

```{r}
summary(lm.fit)
```

We can use `names()` function in order to find out what other
pieces of information are stored in `lm.fit`. Although we can
extract these quantities by name, `lm.fit$coefficients`, it is
safer to use the extractor function like `coef()` to access them.

```{r}
names(lm.fit)
lm.fit$coefficients
coef(lm.fit)
```

In order to obtain a confidence interval for the coefficient
estimates, we can use the `confint()` command.

```{r}
confint(lm.fit)
```

The `predict()` function can be used to produce confidence
intervals and prediction intervals for the prediction of `medv`
for a given value of `lstat`.

```{r}
predict(lm.fit, data.frame(lstat=c(5,10,15)),
        interval="confidence")
predict(lm.fit, data.frame(lstat=c(5,10,15)),
        interval="prediction")
```

The 95% confidence interval associated with `lstat` value of
10 is (24.47, 25.63), and the 95% prediction interval is
(12.828, 37.28). As expected, the confidence and prediction
intervals are centered around the same point (25.05 for `medv`
when `lstat` equals 10), but the latter are substantially wider.

We will now plot `medv` and `lstat` along with the least squares
regression line using the `plot()` and `abline()` functions.

The `abline()` function can be used to draw any line, not just
the least squares regression line. To draw a line with intercept
`a` and slope `b`, we type `abline(a,b)`. The `lwd=3()` command 
causes the width of the regression line to be increased by a 
factor of 3; this works for the `plot()` and `lines()`  function
also. We can use the `pch` option to create different plotting
symbols.

```{r}
plot(Boston$lstat,Boston$medv)
abline(lm.fit, lwd=3,col="red")
```

Four diagnostic plots are automatically produced by
applying the `plot()` function directly to the output from `lm()`.
It is often convenient to view all four plots together. We can
achieve this by using the `par()` function, which tell `R` to
split the display screen into separete panels so that multiple 
plots can be viewed simultaneously.

```{r}
par(mfrow=c(2,2))
plot(lm.fit)
```

Alternatively, we can compute the residuals from a linear 
regression fit using the `residuals()` function. The function
`rstudent()` will return the studentized residuals, and we 
can use this function to plot the redisuals against the
fitted values.

```{r}
plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
```

On the basis of the residuals plots, there is some evidence
of non-linearity. Leverage statistics can be computed for any
number of predictors using the `hatvalues()` function.

The `which.max()` function identifies the index of the largest
element of a vector. In this case, it tells us which obs has
the larsgest leverage

```{r}
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
```

### Multiple Linear Regression

In order to fit a multiple linear regression model using 
least squres, we again use the `lm()` function.

```{r}
lm.fit=lm(medv~lstat+age, data=Boston)
summary(lm.fit)
```

The `Boston` data set contains 13 variables, and so it would be
cumbersome to have to tye all of these in order to perform a
regression using all of the predictors. Instead, we can use the
following short-hand:

```{r}
lm.fit=lm(medv~., data=Boston)
summary(lm.fit)
```

We can access the individual components of a summary object by
name. 

```{r}
summary(lm.fit)$r.sq # give us the R-squared
summary(lm.fit)$sigma # give us the RSE
```

The `vif()` function, part of the `car` package, can be used to
compute variance inflation factors. Most VIF's are low to moderate
for this data.

```{r}
library(car)
vif(lm.fit)
```

What if we would like to perform a regression using all of the
variable but one?

```{r}
lm.fit1=lm(medv~.-age,data=Boston)
summary(lm.fit1)
```

### Interaction Terms

It is easy to include interaction terms in a linear model
using the `lm()` function. The syntax `lstat:black` tells `R`
to include an interaction term between `lstat` and `black`.
The syntax `lstat*age` simultaneously includes `lstat`, `age`,
and the interaction term `lstat`x`age` as predictors; it is
a shorthand for `lstat+age+lstat:age`.

```{r}
summary(lm(medv~lstat*age, data=Boston))
```

### Non-linear Transformations of the Predictors

The `lm()` function can also accomodate non-linear transformations
of the predictors. For instance, given a predictor X, we can
create a predictor X-squared using `I(X^2)`. The function `I()`
is needed since the `^` has a special meaning in a formula;
wrapping as we do allows the standard usage in `R`, which
is to raise `X` to the power `2`. We now perform a regression
of `medv` onto `lstat` and `lstat`-squared.

```{r}
lm.fit2=lm(medv~lstat+I(lstat^2),data=Boston)
summary(lm.fit2)
```

The near-zero p-value associated with the quadratic term suggests
that it leads to an improved model. We use the `anova()` function
to further quantify the extent to which the quadratitc fit is
superior to the linear fit.

```{r}
lm.fit=lm(medv~lstat, data=Boston)
anova(lm.fit,lm.fit2)
```

Here Model 1 represents the linear submodel containing only one
predictor, `lstat`, while Model 2 corresponds to the larger
quadratic model that has two predictors, `lstat` and `last`-squared.
The `anova()` function performs a hypothesis test comparing the 
two models. The null hypothesis is that the two models fit the
data equally well, and the alternative hypothesis is that the
full model is superior. Here the F-statistic is 135 and the
associated p-value is virtually zero. This provides very clear
evidence that the model containing the predictors `lstat` and
`last'-squared is far superior to the model that only contains
the predictor `lstat`. This is not surprising, since earlier we
saw evidence for non-linearity in the relationship between
`medv` and `lstat`. If we type

```{r}
par(mfrow=c(2,2))
plot(lm.fit2)
```

then we see that when the `lstat`-squared term is included in
the model, there is little discernible pattern in the residuals.

In order to create a cubic fit, we can include a predictor of the
form `I(X^3)`. However, this approach can start to get cumbersome
for highr-order polynomials. A better approach involves using
the `poly()` function to create the polynomial within `lm()`.
For example the following command produces a fifth-order
polynomial fit.

```{r}
lm.fit5=lm(medv~poly(lstat,5),data=Boston)
summary(lm.fit5)
```

This suggests that including additional polynomial terms, up to
fifth order, leads to an improvement in the model fit. However,
further investigation of the data reveals that no polynomials
terms beyond fifth order have significant p-values in regression
fit.

Of course, we are in no way restricted to using polynomial 
transformations of the predictors. Here we try a log transformation

```{r}
summary(lm(medv~log(rm),data=Boston))
```

### Qualitative Predictors 

We will now examine the `Carseats` data, which is part of the
`ISLR` library. We will attempt to predict `Sales` in 400
locations based on a number of predictors.

```{r}
names(Carseats)
```

The `Carseats` data includes qualitative predictors such as
`Shelveloc`, an indicator of the quality of the shelving location,
the space within a store in which the car seat is displayed, at
each location. The predictor `Shelveloc` takes on three possible
values, _Bad_, _Medium_ and _Good_.

Given a qualitative variable such as `Shelveloc`, `R` generates
dummy variables automatically. Below we fit a multiple regression
 model that includes some interaction termis.
 
 
```{r}
lm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)
summary(lm.fit)
```

The `contrast()` function returns the coding that `R` uses
for the dummy variables.

```{r}
contrasts(Carseats$ShelveLoc)
```

`R` has created a `ShelveLocGood` dummy variable that takes on a
value of 1 if the shelving location is good, and 0 otherwise.
It has also created a `ShelveLocMedium` dummy variable that 
equals 1 if the shelving location is medium, and 0 otherwise.
A bad shelving location corresponds to a zero for each of the
two dummy variables. The fact that the coefficient for 
`ShelveLocGood`  in the regression output is positive indicates
that a good shelvig location is associated with high sales.
And `ShelveLocMedium` has a smaller positive coefficient,
indicating that a medium shelving location leads to higher
sales than a bad shelving location but lower sales than a good
shelving location.

### Writing Functions

As we have seen, `R` comes with useful functions, and still more
functions are available by way of `R` libraries. However, we
will often be interested in performing an operation for which
no function is available. In this setting, we may want to write
our own function. For instance, below we provide a simple function
that reads in the `ISLR` and `MASS` libraries, called 
`LoadLibraries()`. 
The `{` symbol informs `R` that multiple commands are about to
be input.

```{r}
LoadLibraries=function(){
  library(ISLR)
  library(MASS)
  print("The libraries have been loaded.")
}
LoadLibraries # tell us what is in the function
LoadLibraries() # we call the  function
```

